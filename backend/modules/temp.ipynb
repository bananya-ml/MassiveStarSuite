{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.gaia import Gaia\n",
    "from typing import List\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolve source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Query finished. [astroquery.utils.tap.core]\n"
     ]
    }
   ],
   "source": [
    "def resolve(id:str=None, coords:List=None):\n",
    "    \n",
    "    if id:\n",
    "        job = Gaia.launch_job_async(f\"SELECT gaia3.source_id, gaia3.ra, gaia3.dec, gaia3.parallax, gaia3.parallax_over_error,gaia3.ruwe, gaia3.has_xp_sampled, gaia3ap.classprob_dsc_combmod_star, gaia3ap.classprob_dsc_specmod_star \\\n",
    "                            FROM gaiadr3.gaia_source_lite AS gaia3 \\\n",
    "                            JOIN gaiadr3.astrophysical_parameters AS gaia3ap \\\n",
    "                            ON gaia3.source_id = gaia3ap.source_id \\\n",
    "                            WHERE gaia3.source_id = {source_id}\")\n",
    "        results = job.get_results()\n",
    "    elif coords:\n",
    "        job = Gaia.launch_job_async(f\"SELECT gaia3.source_id, gaia3.ra, gaia3.dec, gaia3.parallax, gaia3.parallax_over_error,gaia3.ruwe, gaia3.has_xp_sampled, gaia3ap.classprob_dsc_combmod_star, gaia3ap.classprob_dsc_specmod_star \\\n",
    "                    FROM gaiadr3.gaia_source_lite AS gaia3 \\\n",
    "                    JOIN gaiadr3.astrophysical_parameters AS gaia3ap \\\n",
    "                    ON gaia3.source_id = gaia3ap.source_id \\\n",
    "                    WHERE gaia3.ra = {coords[0]} AND gaia3.dec={coords[1]}\")\n",
    "        results = job.get_results()\n",
    "    else:\n",
    "        raise ValueError(\"Either 'id' or 'coords' must be provided!\")\n",
    "    \n",
    "    if results.to_pandas().empty:\n",
    "            print(\"No sources found!\")\n",
    "    else:\n",
    "        _check_quality(results.to_pandas())\n",
    "    return results.to_pandas()\n",
    "\n",
    "def _check_quality(results):\n",
    "    if (results['ruwe'] > 1.4).any() or results['parallax'].isnull().any() or (results['parallax_over_error'] <= 3).any():\n",
    "        print(\"The source has poor parameters, it might not be properly resolved.\")\n",
    "\n",
    "    if (results['classprob_dsc_combmod_star']<0.5).any() or (results['classprob_dsc_specmod_star']<0.5).any():\n",
    "        print(\"The source is most likely not a star.\")\n",
    "    \n",
    "    if (results['has_xp_sampled'] != True).any():\n",
    "        print(\"The source has no BP-RP spectrum data in Gaia Data Release 3!\")\n",
    "\n",
    "# test values\n",
    "source_id = '4111834567779557376'\n",
    "ra = '256.5229102004341'\n",
    "dec = '-26.580565130784702'\n",
    "\n",
    "results = resolve(id=source_id)#None,coords=list((ra,dec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_ID</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>parallax</th>\n",
       "      <th>parallax_over_error</th>\n",
       "      <th>ruwe</th>\n",
       "      <th>has_xp_sampled</th>\n",
       "      <th>classprob_dsc_combmod_star</th>\n",
       "      <th>classprob_dsc_specmod_star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4111834567779557376</td>\n",
       "      <td>256.52291</td>\n",
       "      <td>-26.580565</td>\n",
       "      <td>1.153767</td>\n",
       "      <td>47.893497</td>\n",
       "      <td>0.836915</td>\n",
       "      <td>True</td>\n",
       "      <td>0.99992</td>\n",
       "      <td>0.992043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             SOURCE_ID         ra        dec  parallax  parallax_over_error  \\\n",
       "0  4111834567779557376  256.52291 -26.580565  1.153767            47.893497   \n",
       "\n",
       "       ruwe  has_xp_sampled  classprob_dsc_combmod_star  \\\n",
       "0  0.836915            True                     0.99992   \n",
       "\n",
       "   classprob_dsc_specmod_star  \n",
       "0                    0.992043  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_data(results):\n",
    "    retrieval_type = 'XP_SAMPLED'  \n",
    "    data_structure = 'INDIVIDUAL'\n",
    "    data_release   = 'Gaia DR3'\n",
    "    dl_key         = f'{retrieval_type}_{data_structure}.xml'\n",
    "\n",
    "    datalink  = Gaia.load_data(ids=results['SOURCE_ID'], data_release = data_release, retrieval_type=retrieval_type, format = 'csv', data_structure = data_structure)\n",
    "    \n",
    "    for dl_key in datalink.keys():\n",
    "        if 'XP_SAMPLED' in dl_key: \n",
    "            product = datalink[dl_key][0]\n",
    "            \n",
    "            file_name = f\"{dl_key.replace('.xml', '').replace(' ','_').replace('-','_')}\"\n",
    "\n",
    "            print(f'Writing table as: {file_name}')\n",
    "            if os.path.exists('./temp'):\n",
    "                product.write('./temp/'+file_name, format = 'csv', overwrite = True)\n",
    "            else:\n",
    "                os.makedirs('./temp')\n",
    "                product.write('./temp/'+file_name, format = 'csv', overwrite = True)\n",
    "    return\n",
    "\n",
    "pull_data(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference and delete data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]]\n",
      "Deleted ./temp directory and its contents.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "data_dir = './temp'\n",
    "file = '*.csv'\n",
    "\n",
    "# Read the data\n",
    "csv_files = glob.glob(f\"{data_dir}/{file}\")\n",
    "if csv_files:\n",
    "    data = pd.read_csv(csv_files[0])\n",
    "    X = data['flux'].to_numpy()\n",
    "\n",
    "    def inference(model, X):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            output = model(X.unsqueeze(1))\n",
    "            prob = torch.sigmoid(output)\n",
    "            prediction = torch.round(prob).numpy().astype(float)\n",
    "            return prediction\n",
    "\n",
    "    # Load the model\n",
    "    model = torch.jit.load('../models/cnn_ensemble.pth', map_location=torch.device('cpu'))\n",
    "    \n",
    "    # Perform inference\n",
    "    prediction = inference(model, torch.from_numpy(X).float().unsqueeze(0))\n",
    "    print(prediction)\n",
    "\n",
    "    # Delete the entire temp directory\n",
    "    try:\n",
    "        shutil.rmtree(data_dir)\n",
    "        print(f\"Deleted {data_dir} directory and its contents.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error deleting {data_dir} directory: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"No CSV files found in the temp directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
